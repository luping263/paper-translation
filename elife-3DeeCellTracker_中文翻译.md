# 3DeeCellTracker：基于深度学习的 3D 时间序列图像中细胞分割与追踪管道

**作者：** Chentao Wen $^{1 *}$, Takuya Miura $^{2}$, Venkatakaushik Voleti $^{3}$, Kazushi Yamaguchi $^{4,5}$, Motosuke Tsutsumi $^{5,6}$, Kei Yamamoto $^{7,8}$, Kohei Otomo $^{5,6,8}$, Yukako Fujie $^{2}$, Takayuki Teramoto $^{9}$, Takeshi Ishihara $^{9}$, Kazuhiro Aoki $^{6,7,8}$, Tomomi Nemoto $^{5,6,8}$, Elizabeth MC Hillman $^{3}$, Koutarou D Kimura $^{1,2,10}$

$^{1}$ 名古屋市立大学研究生院理学研究科，名古屋，日本；$^{2}$ 大阪大学研究生院理学研究科生物科学系，丰中，日本；$^{3}$ 哥伦比亚大学生物医学工程系、放射学系及祖克曼心智大脑行为研究所，纽约，美国；$^{4}$ 北海道大学信息科学技术研究生院，札幌，日本；$^{5}$ 生理学研究所，冈崎，日本；$^{6}$ 生命与生命系统探索研究中心，冈崎，日本；$^{7}$ 自然科学研究机构基础生物学研究所，冈崎，日本；$^{8}$ 综合研究大学院大学，叶山，日本；$^{9}$ 九州大学理学部生物学系，福冈，日本；$^{10}$ 理化学研究所先进智能项目中心，东京，日本

\*通讯作者：chentao-wen@umin.ac.jp

**利益冲突：** 作者声明不存在利益冲突。

**资助：** 见第 33 页

**收到日期：** 2020 年 5 月 21 日

**接受日期：** 2021 年 2 月 23 日

**发表日期：** 2021 年 3 月 30 日

**审稿编辑：** Manuel Zimmer，分子病理学研究所，维也纳生物中心及维也纳大学，奥地利

(c) Copyright Wen et al. 本文根据知识共享署名许可协议分发，允许在注明原作者和来源的情况下不受限制地使用和再分发。

---

## 摘要

尽管显微镜技术最近有所改进，但在三维时间序列图像（$3 \mathrm{D}+\mathrm{T}$ 图像）中分割和追踪细胞以提取其动态位置和活动仍然是该领域的一个相当大的瓶颈。我们开发了一个基于深度学习的软件管道 3DeeCellTracker，它整合了多种现有和新技术，包括用于追踪的深度学习。仅使用一个训练数据体积、一次初始校正和少量参数更改，3DeeCellTracker 成功地在半固定和"拉直"的自由移动线虫大脑、自然跳动斑马鱼心脏中分割和追踪了约 100 个细胞，并在 3D 培养的肿瘤球体中追踪了约 1000 个细胞。虽然这些数据集是用高度不同的光学系统成像的，但我们的方法在大多数情况下追踪了 90-100% 的细胞，这与之前的结果相当或更优。这些结果表明，3DeeCellTracker 可能为揭示难以分析的图像数据集中的动态细胞活动铺平道路。

---

## 引言

由于近年来显微镜硬件的显著发展，对细胞进行成像以揭示生命的动态活动已变得相当可行（Frigault et al., 2009; Ahrens and Engert, 2015; Bouchard et al., 2015; Weisenburger and Vaziri, 2018）。此外，已开发出多种用于处理 2D/3D 静态图像和 $2 \mathrm{D}+\mathrm{T}$ 图像的软件平台（Eliceiri et al., 2012）。

然而，处理 $3 \mathrm{D}+\mathrm{T}$ 图像中的细胞仍然很困难，特别是当细胞无法清晰分离和/或其运动相对较大时，例如变形器官中的细胞。要处理 $3 \mathrm{D}+\mathrm{T}$ 图像中的对象，需要以下两个步骤：（1）分割：将每个 3D 图像中的感兴趣区域分割成单个对象（图 1-图补充 1，左）；（2）追踪：将特定体积中的对象与时间相邻体积中的同一对象链接（图 1-图补充 1，右）。对于在 $3 \mathrm{D}+\mathrm{T}$ 图像中分割和追踪（以下统称为"追踪"）变形器官的细胞，已开发出针对特定条件下处理图像进行优化的程序（Schröder et al., 2013; Toyoshima et al., 2016; Venkatachalam et al., 2016; Nguyen et al., 2017）。然而，这些方法不能用于其设计条件之外的其他条件，至少在没有处理效率损失的情况下不能使用。换句话说，$3 \mathrm{D}+\mathrm{T}$ 图像，特别是在具有挑战性的条件下获得的图像，只有在专门为这些图像开发定制软件时才能有效处理。原因之一是必须优化许多参数才能获得良好的结果——例如，即使在 2D 图像处理中，光照的变化也可能需要重新优化分割和追踪的参数（Egnor and Branson, 2016）。

---

## eLife 摘要

显微镜自 17 世纪以来一直被用于解密生命的微小细节。现在，3D 显微镜的出现使科学家能够构建活细胞和组织的详细图像。在这一努力中，自动化正变得越来越重要，以便科学家能够分析由此产生的图像并了解身体如何生长、愈合和响应诸如药物治疗等变化。

特别是，算法可以帮助在图片中识别细胞（称为细胞分割），然后在多个图像中随时间跟踪这些细胞（称为细胞追踪）。然而，在给定时间段内对 3D 图像执行这些分析一直相当具有挑战性。此外，已经创建的算法通常不用户友好，并且它们只能应用于通过特定科学方法收集的特定数据集。

作为回应，Wen 等人开发了一个名为 3DeeCellTracker 的新程序，它在台式计算机上运行，并使用一种称为深度学习的人工智能来产生一致的结果。关键是，3DeeCellTracker 可用于分析使用不同类型的尖端显微镜系统拍摄的各种类型的图像。实际上，该算法随后被用于追踪移动的微小线虫中的神经细胞活动、幼小鱼类中跳动的心脏细胞活动，以及在实验室中培养的癌细胞活动。这种多功能工具现在可以在生物学、医学研究和药物开发中使用，以帮助监测细胞活动。

---

### 概述

我们开发了一个新的管道 3DeeCellTracker，它整合了新颖和现有技术（图 1A）。经过预处理（见材料与方法）后，它使用 3D U-Net 对所有 $3 \mathrm{D}+\mathrm{T}$ 图像中的细胞进行自动分割，将单个体素分类为细胞或非细胞类别（Ronneberger et al., 2015; Çiçek et al., 2016）。连续的"细胞"体素区域使用分水岭方法（watershed method）（Beucher and Meyer, 1993）分离成单个细胞区域，然后进行编号。分割的细胞仅在第一个体积的 3D 图像中进行手动校正。在随后的 3D 追踪步骤中，我们通过引入深度学习技术前馈网络（feedforward network, FFN）来预测基于先前和当前图像之间保持的细胞空间模式的细胞位置，从而显著提高了效率。预测的位置通过称为 PR-GLS（Ma et al., 2016）的非刚性点集配准方法和我们的自定义方法进行校正，以获得精确的细胞位置，这对于提取准确的细胞信号动态至关重要。

3D U-Net 和 FFN 使用手动确认的数据或来自单个 3D 图像体积的合成数据进行预训练（图 1B、C）。追踪结果通过将追踪细胞的位置与相应的原始图像进行比较进行视觉检查（图 1-图补充 2）。我们方法的关键是使用模拟来为 FFN 产生大量训练数据，以及为 FFN 精心设计的后处理方法，这使得在非常不同的 $3 \mathrm{D}+\mathrm{T}$ 数据集中能够灵活且稳健地追踪移动细胞。在以下两个部分中，我们描述了分割和追踪方法的细节。

### 分割

对于分割，图像中类似细胞的区域应该被分割成可能在强度、大小、形状和纹理方面不同的单个细胞。使用深度网络在 2D 图像中进行细胞分割已有报道（Ronneberger et al., 2015; Van Valen et al., 2016; Bannon et al., 2018）。在本研究中，我们利用称为 3D U-Net 的深度网络来分割 3D 图像中的细胞，基于相邻体素中包含的信息预测单个体素的类别标签（细胞或非细胞）（图 2A 和图 2-图补充 1; Ronneberger et al., 2015; Çiçek et al., 2016）。U-Net 可以在不同的成像条件下产生精确的分割，并且可以用非常少的标注图像进行训练（例如，在本研究中仅使用一个 3D 图像体积；见图 1B）。

第一个体积的预处理图像用于训练 3D U-Net（图 1B），然后训练好的 U-Net 用于所有后续体积中细胞的分割。一旦在一个数据集上训练，3D U-Net 可以直接重用于在相似光学条件下获得的不同数据集。使用 3D U-Net 检测到的类似细胞的区域使用分水岭方法进行分组并分离成单个细胞（见图 2A 和材料与方法）。

### 追踪

对于追踪细胞，可以考虑两种主要策略。一种策略是利用每个细胞区域中包含的信息，例如局部峰值或强度分布（Toyoshima et al., 2016）。使用这些信息，程序可以通过在下一个体积的附近区域中搜索其新位置来更新每个细胞的位置。然而，这种策略的明显缺点是，如果细胞的运动与相邻细胞之间的距离相当或更大，则可能被错误追踪（见下文）。

另一种策略是用它们的中心点表示细胞，忽略每个细胞区域中的信息，将细胞视为一组点。在这种策略中，下一个体积中细胞集的新位置可以基于其空间分布的模式进行估计，并且具有大运动的细胞也可以基于运动的全局趋势进行追踪。先前报道的利用这种策略的方法，称为点集配准（point set registration）（Ma et al., 2016; Jian and Vemuri, 2005; Myronenko et al., 2006），使用空间分布和运动的一致性来追踪人工数据集中的点。然而，空间模式通常由专家设计的特征来表征，这种方法在本研究使用的细胞图像中效果不佳（参考下面关于快速点特征直方图 [FPFH; Rusu et al., 2009] 与 FFN 的结果）。这种策略的另一个问题是，估计的位置并不总是准确的，因为忽略了每个细胞区域中包含的信息（见下面关于我们精确校正方法的结果）。

为了获得更稳健和准确的追踪结果，我们整合了空间模式（即点集）和局部细胞区域策略，并使用深度学习技术 FFN 来处理前者。我们使用 FFN 基于每个细胞与其 20 个周围细胞之间的距离模式来匹配时间相邻的细胞（图 2B）。使用 FFN 获得的模式，$t_1$ 时的所有细胞与 $t_2$ 时的所有细胞进行比较，最相似的细胞被视为 $t_1$ 和 $t_2$ 时的同一细胞，这个过程我们称为初始匹配（initial matching）。

尽管深度网络技术有望产生优异的细胞追踪结果，但由于需要大量训练数据，该方法之前未被使用。这些数据难以手动准备，特别是对于 $3 \mathrm{D}+\mathrm{T}$ 图像，因为通过沿 z 轴切换多个层来验证和校正大量细胞位置随时间的变化实际上是不可能的。为了解决为 FFN 准备训练数据的这一困难，我们通过模拟细胞运动生成了超过 500,000,000 个合成训练数据点（见图 2-图补充 2 和材料与方法）。

在管道中，从由 3D U-Net 和分水岭方法分割的细胞区域中提取细胞中心点，并将预训练的 FFN（图 1C 和 2B）应用于细胞点，以从体积 $t$ 到 $t+1$ 生成初始匹配（图 2C，面板 2-2 和 4-1）。为了改进初始匹配，使用非刚性点集配准方法（PR-GLS）（Ma et al., 2016）生成一致变换，即相邻细胞应该具有相似的运动（图 2C，面板 4-2）。最初，PR-GLS 与 FPFH 方法结合使用来预测细胞位置（Ma et al., 2016）；然而，我们的 FFN 产生的初始匹配比 FPFH 更准确（图 2-图补充 3A 和 B），我们的 FFN + PR-GLS 组合产生的细胞位置预测比 FPFH + PR-GLS 或经典仿射对齐（affine alignment）（Myronenko et al., 2006）更准确（图 2-图补充 3C 和 D）。然而，我们的方法有时会产生细微的错误，因为某些细胞可能表现出与其相邻细胞略有不同的运动，这些错误可能随时间累积而变大。为了克服这些错误，估计的位置被精确校正，通过利用 3D U-Net 输出中包含的局部细胞区域信息来补偿它们的差异（图 2C，面板 5，图 2-图补充 4，和材料与方法）。

### 追踪变形线虫全脑中的神经元

为了测试 3DeeCellTracker 的性能，我们分析了秀丽隐杆线虫（C. elegans）变形大脑中神经元的 $3 \mathrm{D}+\mathrm{T}$ 图像。秀丽隐杆线虫由于其小的大脑（成年个体中约 40 mm³）在透明体内、302 个神经元的所有连接的完整描述、使用基因编码钙指示剂（GECI）的可行性，以及在其小大脑中的感知、记忆和决策能力，已被用作对大脑中所有神经元活动进行成像（"全脑成像"）的模型（de Bono and Maricq, 2005）。来自几个实验室的秀丽隐杆线虫全脑成像已有报道，目前最流行的光学系统是转盘共焦系统（spinning disk confocal system），每个实验室都开发了自己的追踪软件（Schrödel et al., 2013; Toyoshima et al., 2016; Venkatachalam et al., 2016; Nguyen et al., 2017）。我们建立了自己的转盘共焦系统用于全脑成像，OSB-3D（见材料与方法了解详情），并从我们实验室建立的品系和先前研究中使用的品系获得了全脑活动的 $3 \mathrm{D}+\mathrm{T}$ 图像（Nguyen et al., 2016）（数据集线虫 #1 和 #2，分别）。此外，我们分析了先前使用不同光学系统发布的全脑图像（Toyoshima et al., 2016; 数据集线虫 #3）。在所有数据集中，线虫通过麻醉（线虫 #1 和 #2）或约束（线虫 #3）半固定，红色荧光蛋白和 GECI 分别用于监测细胞位置和细胞活动。

分割后，我们在第一个体积的 $3 \mathrm{D}+\mathrm{T}$ 图像中手动确认了头部 164 个神经元，其中细胞信号的分布大部分（但不是完全）与背景信号分离（数据集线虫 #1a; 见图 3A-C）。当线虫被麻醉时，其头部变形，细胞在成像过程中移动。我们的方法追踪了所有 171 个体积中的所有神经元，除了那些移出相机视野的神经元（图 3D-F，图 3-视频 1）。

为了评估追踪具有大运动细胞的困难，我们计算了相对运动（relative movement, RM）的分数，即细胞的运动除以从该细胞到其最近相邻细胞的距离。当 RM 较小时，搜索最近的细胞是在下一个体积中找到给定细胞新位置的最简单方法。然而，当 RM ≥ 0.5 时，这种简单的方法可能导致追踪错误（图 4 和材料与方法）。尽管线虫 #1 数据集中的大多数细胞 RM 值 ≤ 0.5（图 3B，底部），但其他数据集中有 RM ≥ 0.5 的细胞；尽管如此，这些也被我们的程序成功追踪（见下文）。

我们还测试了线虫 #1b 数据集，该数据集与线虫 #1a 来自同一品系（图 3-图补充 1），我们再次实现了 100% 的追踪准确率，除了噪声水平外没有更改任何参数（见表 1 和 2）。两个数据集中细胞核的位置信息随后用于基于 GECI 强度提取神经元的钙动态，这反映了线虫大脑中神经元的自发活动（图 5，图 5-图补充 1 和图 5-视频 1）。

相同的方法应用于在我们实验室使用相同 OSB-3D 系统获得但来自先前全脑成像研究中使用的线虫品系神经元的 $3 \mathrm{D}+\mathrm{T}$ 图像（Nguyen et al., 2016; AML14 品系，数据集线虫 #2; 图 3-图补充 2A）。我们的方法再次实现了 100% 的追踪准确率，并从所有 101 个神经元中提取了钙信号，尽管该数据集在线虫 #1 数据集方面在核标记强度和运动模式方面存在显著差异（图 3-图补充 2A-F，图 3-视频 2 和图 5-视频 2）。应该注意的是，使用我们的方法检测到的神经元比使用原始方法检测到的更多（约 90 个或更少）（Nguyen et al., 2016）。

我们还应用我们的方法到一个公开可用的数据集，该数据集使用与线虫 #1 和 #2 数据集不同的品系、不同的显微镜设置和不同的成像条件获得（线虫 #3，图 3-图补充 3A; Toyoshima et al., 2016）。在这种情况下，线虫在微流控设备中松散约束且未麻醉，因此与线虫 #1 和 #2 数据集相比，表现出更大的头部变形和体积之间的细胞位移（约三倍）（图 3-图补充 3A 和 B）。此外，该数据集具有较低的分辨率（x 和 y 方向的分辨率的一半）。尽管如此，通过少量参数修改（表 2 和材料与方法），我们的方法正确追踪了 171/175（=98%）的神经元（图 3-图补充 3C-F 和图 3-视频 3）。我们的结果与原始报告相当，其中 198 个神经元中有 171 个被无错误追踪（Toyoshima et al., 2016）。这些结果表明，我们的方法可以灵活地处理在不同条件下获得的半固定线虫大脑中神经元的 $3 \mathrm{D}+\mathrm{T}$ 图像。

### 追踪自由移动线虫大脑中的神经元

为了揭示神经元活动与动物行为之间的关系，Nguyen 等人开发了一种追踪自由移动线虫中神经元的方法，其中大脑的变形和神经元的运动比半固定线虫中发生的要大得多（Nguyen et al., 2016; Nguyen et al., 2017）。在"拉直"线虫并分割其神经元后，他们制作了一组参考体积，每个神经元都与之匹配以分配其身份。尽管这种方法很强大，但它需要高性能科学计算集群同时运行多达 200 个核心。因此，我们测试了在台式 PC 上实现的 3DeeCellTracker 是否可以处理如此具有挑战性的数据集（线虫 #4）。

通过少量修改（见材料与方法），我们使用 3DeeCellTracker 分割并追踪了线虫 #4 数据集初始 500 个体积中的 113 个细胞。这里我们分析了通过拉直方法预处理的图像（Nguyen et al., 2017），这对我们当前的方法是必要的。即使在拉直之后，细胞运动仍然很大，许多与细胞之间的距离相当，即 RM ≥ 0.5（图 6A 和 B）。我们视觉检查了 90 个细胞的追踪，而剩余的 23 个由于弱强度/光漂白和/或细胞在密集区域中的困难而未检查。注意，原始报告中检查了 70 个细胞（Nguyen et al., 2017）。我们发现 90 个细胞中有 66 个（73%）被正确追踪，没有错误（图 6D-F，单模式），这是可接受的但不是理想的。

为了进一步改进我们方法对大细胞运动的处理，我们开发了一种新模式，其中从不同的先前时间点进行多个细胞位置预测，最终预测取这些预测的平均值。我们称此为"集成模式"（ensemble mode），之前的方法为"单模式"（single mode），其中时间 $t$ 的细胞位置预测来自 $t-1$ 的结果（图 6C）。

当应用集成模式时，我们再次发现 66 个细胞被正确追踪，没有错误，剩余的 24 个细胞在大多数体积中被正确追踪（94%-98.2%）。这比单模式有显著改进，在单模式中，$t$ 时的错误一直保持到追踪结束（图 6D-F，集成模式; 图 6-视频 1）。总的来说，集成模式正确追踪了 45,000 个细胞运动中的 44,905 个（99.8%），这一结果至少与原始报告相当（Nguyen et al., 2017）。从两个示例细胞的轨迹中，我们发现大运动，包括沿 z 轴的运动（跨越约 30 层），频繁发生（图 6G），证明了我们的方法在台式 PC 上在这个包含相当大的大规模运动的挑战性数据集上的优异性能。然而，由于集成模式需要比单模式更长的追踪时间（分别为 10 分钟/体积与 2 分钟/体积），我们在以下分析中使用了单模式。

### 追踪使用 SCAPE 系统获得的跳动斑马鱼心脏图像中的细胞

为了测试 3DeeCellTracker 的通用适用性，我们将我们的方法应用于使用 SCAPE 2.0 系统（Voleti et al., 2019; 图 7A）以每秒 100 个体积的速度获得的斑马鱼幼体自然跳动心脏的 $3 \mathrm{D}+\mathrm{T}$ 图像。该系统的图像采集速度相对于转盘共焦系统来说是异常的，后者通常允许记录 ≤10 个体积/秒。该数据集包括具有较强强度的大细胞（易于分割）和具有较弱强度的小细胞（难以分割）（图 7B，顶部和中部）。数据集中的光漂白使得在成像的后期部分检测和追踪弱强度细胞变得具有挑战性，因为小细胞信号和背景信号之间存在大量重叠（图 7B; 图 7-图补充 1）。这种弱强度是由于系统的极快扫描速率（每秒 10,568 帧）而不可避免的。此外，心脏的快速跳动导致所有细胞在 x-y-z 方向上的相对较大运动（图 7B，底部; 图 7-视频 1; 见下文），使得细胞追踪比线虫 #1-3 更具挑战性，后者主要在 x-y 平面移动。

分割后，我们在第一个体积中手动确认了 98 个细胞并自动追踪它们（图 7C 和 D; 图 7-视频 2）。我们发现，在 30 个较大细胞（大小：157-836 体素）中，有 26 个（87%）在所有 1000 个体积中被正确追踪。尽管具有较低强度的较小细胞更难追踪，但当包括它们时，我们仍然正确追踪了 98 个细胞中的 66 个（67%）（图 7E 和 F）。两个示例细胞的追踪运动在 3D 空间中显示出规则振荡（x、y 和 z 轴; 图 7G），与心脏的规则跳动运动一致。应该注意的是，除了少量参数更改外，我们没有优化斑马鱼数据的管道程序（表 2）。我们的结果表明，3DeeCellTracker 也能够分析从显著不同的光学系统获得的具有快速和动态运动的 3D 空间图像。

然后我们使用追踪结果来回答一个生物学问题：细胞内钙信号与心脏跳动周期之间的关系是什么？我们提取了正确追踪的 66 个心脏细胞的钙动态，它们与线虫数据集一样共表达 GECI，并分析了这些细胞相对于心室和心房区域跳动周期的活动相位。如图 7H 和 I 所示，钙信号在很大程度上与跳动周期同步。尽管部分心脏细胞（总共 98 个中的 32 个）未被正确追踪，因此未被分析，但这一结果仍然值得注意，因为追踪的细胞显示了体内钙动态与自然心跳之间的关系。这种关系的观察只有通过能够监测每秒 100 个体积的最先进显微镜系统和我们能够正确追踪 3D 空间中相应细胞运动大部分的软件管道的发展才成为可能。

### 追踪使用双光子显微镜成像的 3D 肿瘤球体中的约 900 个细胞

我们还测试了我们的方法在更相关的生物医学应用数据集上，即使用双光子显微镜成像的 3D 多细胞肿瘤球体（MCTS）中约 900 个细胞的数据集。3D MCTS 由于其与体内肿瘤细胞的相似性，越来越多地用于药物筛选（Riedl et al., 2017）。因此，测量 3D MCTS 中单个细胞活动已变得必要，尽管追踪 3D MCTS 的 $3 \mathrm{D}+\mathrm{T}$ 图像中大量细胞的运动一直是一个相当大的挑战。

我们获得了表达 FRET 型 ERK 传感器 EKAREV-NSL（Komatsu et al., 2011）的 3D MCTS 细胞的 $3 \mathrm{D}+\mathrm{T}$ 图像，使用双光子显微镜（见材料与方法）。该数据集显示强度和运动的正常分布，但包括比线虫大脑或斑马鱼心脏数据集更多的细胞（图 8A 和 B; 图 8-视频 1）。此外，在成像过程中发生了细胞分裂和死亡。我们的方法分割并追踪了 901 个细胞，其中我们视觉检查了 894 个细胞的追踪结果（剩余的 7 个细胞在体积 #1 中发现有分割错误）。我们排除了在事件发生后经历细胞死亡或细胞分裂的细胞，发现 894 个细胞中有 869 个（97%）被正确追踪（图 8C-E，图 8-视频 2）。使用追踪结果，我们从 FRET 信号中提取了 ERK 活性。在三个具有跨层运动的代表性细胞中，我们确认提取的信号正确反映了细胞中的强度变化（图 8F）。我们还发现球体整体向下移动，尽管每个细胞向不同方向移动（图 8G）。

### 使用退化数据集在挑战性条件下评估方法

在前面部分描述的评估中，我们成功分析了在图像分辨率、信噪比和细胞运动类型等方面不同的多种类型数据集。然后我们使用通过修改线虫 #3 数据集获得的一系列退化数据集，系统地评估了我们的方法（单模式）在各种条件下的性能。为了公平比较，我们使用了相同的预训练 3D U-Net 和在原始线虫 #3 数据集上使用的相同手动校正分割（$t=1$）。

分割的一般困难来自具有低信噪比的图像。过多的噪声可能掩盖真实的细胞信号，导致不正确的分割，最终导致不正确的追踪。我们在三个向原始图像添加不同水平泊松噪声的退化数据集中追踪细胞：sd=60、sd=100 和 sd=140（图 9A）。原始图像中非细胞区域的噪声水平为 sd=4.05，中位强度为 411，而细胞区域的中位强度为 567，95% 置信区间为 430-934，表明非细胞和细胞区域之间存在微小重叠（图 3-图补充 3B）。在 sd=60 条件下，非细胞和细胞区域的强度重叠程度更大（图 9B），图像质量看起来比原始图像差（图 9A）。尽管如此，我们的方法实现了低错误率（6/175 = 3%; 图 9C-E）。即使在 sd=140 条件下，其中强度广泛重叠（图 9B）且图像质量相当差（图 9A），我们的方法也实现了可接受的错误率（16/175 = 9%，即 91% 正确; 图 9C-E）。注意，追踪错误率远低于分割错误率（分别为 16/175 与 57/175; 图 9-图补充 1），表明我们基于 FFN 的追踪方法可以补偿细胞分割中的错误。考虑到退化数据集中细胞区域和背景之间强度分布的重叠比真实数据集严重得多（图 9B 和图 3、6、7 和 8 的面板 B），这些结果表明我们的方法可以在具有严重噪声的 $3 \mathrm{D}+\mathrm{T}$ 图像中稳健地追踪细胞。

另一个困难来自追踪过程中体积之间的大细胞位移。我们通过移除线虫 $3 \mathrm{D}+\mathrm{T}$ 图像中的中间体积来增强这种效果，然后测试了三个数据集，分别为原始数据集的 1/2、1/3 和 1/5 体积（图 9F）。正如预期的那样，当移除更多体积时，细胞的运动和追踪错误的数量增加（图 9G-L）。尽管如此，1/3 体积条件下的错误率是可接受的（14/175 = 8%，即 92% 正确），而 1/5 体积条件下的错误率相对较高（25/175 = 14%，即 86% 正确）。

然后我们测试了我们的方法是否可以追踪沿 z 轴的细胞运动，其中分辨率远低于 x-y 平面中的分辨率。在这种情况下，沿 z 轴的 $3 \mathrm{D}+\mathrm{T}$ 追踪比 x-y 2D 平面更具挑战性。在变形线虫和肿瘤球体数据集中，沿 z 轴的分辨率约为 x-y 平面中的 1/10-1/5（图 3、图 3-图补充 1、2 和 3 以及图 8 的面板 A）。我们确认线虫 #1a、#1b 和 #3 以及肿瘤球体数据集中分别有 5、16、25 和 668 个细胞显示沿 z 轴的跨层运动。尽管如此，我们的方法正确追踪了所有这些细胞。例如，虽然线虫 #3 数据集中的两个细胞表现出多次跨层运动（图 9-图补充 2），但它们被正确追踪直到序列结束。此外，我们还退化了斑马鱼心脏数据，以测试我们的方法是否可以追踪具有不等分辨率的动态 3D 细胞运动。即使斑马鱼图像在 z 轴上的分辨率通过总和分箱（sum binning）降低，收缩因子 = 2，我们的方法也能够正确追踪大部分细胞（30 个较大细胞中的 80% 和所有 98 个细胞中的 53%; 表 3）。总之，这些结果表明我们的方法可以在各种条件下正确追踪细胞，包括严重噪声、大运动和不等分辨率。

### 挑战性运动及其与追踪错误率的关系

为了评估我们的方法在具有大运动的数据集上的追踪性能，我们总结了 RM 值，这些值列在表 3 和图 10 中（另见图 4）。尽管线虫 #3 和斑马鱼数据集中的许多细胞运动具有 RM ≥ 0.5，但大多数线虫神经元和斑马鱼心脏中的较大细胞通过单模式被正确追踪。此外，我们的程序使用集成模式实现了"拉直"自由移动线虫神经元的 99.8% 追踪，而该数据集中的许多细胞运动具有 RM ≥ 1。这些结果表明我们的方法能够分析具有挑战性位移的图像。

为了研究细胞运动与追踪错误率之间的关系，我们绘制了每个体积的平均 RM 和相应错误率的散点图（图 10-图补充 1）。回归线指示的结果表明 RM 与错误率之间存在正相关，尽管相关趋势似乎因数据集而异，这意味着运动不是影响错误率的唯一因素。我们还绘制了使用集成模式追踪的线虫 #4 数据集的散点图和回归线（图 10-图补充 2）。结果表明错误率与运动不相关，可能是因为在集成模式中，细胞位置是从多个不同体积预测的，因此来自先前体积的运动与错误率没有密切关系。

### 我们的方法与之前两种方法的追踪准确率比较

为了进一步评估我们方法的能力，我们将我们方法的追踪性能与另外两种最先进的细胞追踪方法进行了比较。第一种是 DeepCell 2.0，这是 DeepCell 的新版本，它是使用深度学习在 $2 \mathrm{D}+\mathrm{T}$ 图像中分割和追踪细胞的先驱（Bannon et al., 2018）。与我们的方法不同，DeepCell 2.0 主要在包括细胞分裂、出生和死亡的图像上进行了测试，但未在变形器官的图像上进行测试。第二种是 Toyoshima 等人开发的软件，它不使用深度学习技术，但在线虫全脑数据集的分割和追踪方面达到了比任何其他先前方法更高的准确率（Toyoshima et al., 2016）。

在我们的线虫大脑数据集上，DeepCell 2.0 追踪了约 10% 的细胞（图 11A，图 11-图补充 1A，图 11-视频 1，和表 4）；这可能是因为 DeepCell 2.0 的追踪算法针对与细胞分裂相关的运动进行了优化，但未针对快速变形的器官。Toyoshima 的方法追踪了原始线虫 #3 神经元的约 90%，但仅追踪了退化的"线虫 #3，1/5 采样"的约 10%（图 11B，图 11-图补充 1B，和表 4）。在斑马鱼数据集上测试时，Toyoshima 的方法仅能检测到 76 个细胞，并遗漏了一些弱强度细胞，表现不如我们的方法（检测到 98 个细胞）。在检测到的 76 个细胞中，21 个从第一个体积开始就被错误追踪，可能是因为他们的方法在分割后自动使用高斯分布重新拟合细胞形状，这在拟合弱强度细胞时可能导致失败。他们的追踪准确率也低于我们的（表 4）。此外，我们的方法在运行时间方面被发现与 DeepCell 2.0 和 Toyoshima 的方法相当或更高效（表 5）。这些结果表明，我们的方法比先前的方法更有能力追踪 $3 \mathrm{D}+\mathrm{T}$ 图像中的细胞。

---

## 讨论

追踪 $3 \mathrm{D}+\mathrm{T}$ 图像中的生物对象已被证明是困难的，各个实验室仍然经常需要开发自己的软件来从使用不同光学系统和/或成像条件获得的图像中提取重要特征。此外，即使使用相同的光学系统，通常也需要为不同数据集优化许多参数。为了解决这些问题，我们开发了一个基于深度学习的管道 3DeeCellTracker，并证明它可以灵活地应用于在不同条件和/或不同质量下获得的多样化数据集。我们分析了线虫、斑马鱼和肿瘤球体的多个图像系列，它们在核标记、强度水平、噪声水平、每个图像的细胞数量、图像分辨率和大小、成像速率和细胞速度方面不同。值得注意的是，我们表明我们的方法在这些数据集中的挑战性条件下成功追踪了细胞，例如大运动（见图 10、表 3 和材料与方法）、跨层运动（图 6G 和 7G，以及图 9-图补充 2）和弱强度条件（图 7B，图 7-图补充 1，图 7-视频 1）。此外，我们的方法在至少具有挑战性成像条件下的变形器官中优于两种先前的最先进细胞追踪方法（图 11，图 11-图补充 1，和表 4），而其他方法可能更适合其他条件。此外，我们的方法在运行时间方面与先前的方法相当或更高效（表 5 和材料与方法）。在台式 PC 上以集成模式运行，我们的方法以高准确率追踪了"拉直"自由移动线虫的神经元，这在先前的研究中需要多达 200 个核心的计算集群（Nguyen et al., 2017）。

我们认为我们方法的高准确率和稳健性基于其使用 FFN（一种深度学习技术）以及其用于追踪的后处理方法（图 2-图补充 3）。如上所述，尽管深度学习技术预计在 3D 细胞追踪中表现出优异的性能，但由于难以手动准备大量训练数据，特别是对于 $3 \mathrm{D}+\mathrm{T}$ 图像，它们迄今为止未被使用。为了解决这个问题，我们通过对单个体积的线虫 3D 细胞位置数据进行人工修改生成了合成训练数据集，这通过我们的方法产生了优异的性能。这些结果表明，深度网络技术可以通过使用合成点集数据集用于细胞追踪，尽管生成数据集的程序很简单。

我们的方法不仅灵活高效，而且研究人员可以轻松使用。例如，我们的方法在所有测试的多样化条件下都表现良好，只需少量修改。值得注意的是，在恒定成像条件下，我们的方法可以直接重用，无需修改任何参数，除了噪声水平（表 1 和 2），这对最终用户很方便。这与传统图像处理方法不同，在传统方法中，获得数据的细微差异，例如光强度、分辨率、目标对象的大小等，通常需要通过试错重新设置多个参数。即使成像条件发生显著变化，我们的方法也只需要少量修改，主要是在分割过程中：（1）修改 3D U-Net 的结构（可以跳过此步骤，因为相同结构的 3D U-Net 可以通过重新训练适应新数据集；见材料与方法）；（2）重新训练 3D U-Net；以及（3）根据成像条件修改参数（见表 1 和 2 以及 https://github.com/WenChentao/3DeeCellTracker 中的"Guide for parameters.md"文件）。对于重新训练 3D U-Net，手动标注通常需要 2-3 小时用于 150-200 个细胞，网络可以在我们的台式 PC 上使用单个 GPU 自动训练 1-2 小时。用于追踪的 FFN 通常不需要重新训练。由于使用深度学习，我们方法中需要手动确定的参数数量远少于传统方法（表 1）。参数可以根据我们在 GitHub 存储库中提供的指南快速修改（在 1 小时内）。

然而，我们的方法可以在两个方面进行改进：更可靠的追踪和简化的程序。追踪可靠性可能受到大运动、弱强度和/或光漂白的影响。正如我们的结果所示（图 6），诸如自由移动线虫中的大运动可以使用集成模式解决，该模式借鉴了机器学习中集成学习的思想，即使用多个预测的平均值来减少预测错误（Polikar, 2009）。类似的想法，使用多个参考体积和聚类方法而不是平均来匹配细胞，在先前的研究中得到了应用（Nguyen et al., 2017），表明集成学习是解决挑战性运动的好方法。另一方面，弱强度和光漂白的问题仍有待解决。一种可能的方法是对强度进行归一化以获得随时间相似的图像，尽管这样做可能不容易。

为了进一步简化整个程序，我们考虑开发结合额外步骤的新网络结构。U-Net 和 3D U-Net 是用于语义分割的网络，它们将每个体素分类为特定类别，即细胞或非细胞区域。除此之外，已经设计了网络通过进一步将同一类别中的对象分离成单个对象来实现实例分割，消除了使用分水岭来分离连接细胞的需要。尽管这些架构最近取得了进展，但重点仍然是在 2D 图像中分割常见对象（Liang et al., 2016; Romera-Paredes and Torr, 2016; He et al., 2017）。我们建议实例分割是未来研究中简化和改进细胞分割的可能方法。另一个可能的改进领域是使用 FFN 进行追踪。通过进一步改进 FFN 结构并使用更多训练数据，网络应该能够生成更准确的匹配，可以直接用于追踪细胞，而无需点集配准。

我们主要使用半固定线虫数据集开发了 3DeeCellTracker。然而，它也成功处理了使用 SCAPE 2.0 系统获得的斑马鱼数据集的 $3 \mathrm{D}+\mathrm{T}$ 图像（Voleti et al., 2019）。该系统与用于线虫数据集的转盘共焦系统在分辨率、z 深度和应用的光学切片原理方面非常不同（Bouchard et al., 2015）。虽然 SCAPE 是一种原始且出色的方法，能够实现超高速 $3 \mathrm{D}+\mathrm{T}$ 图像采集，但一直难以获得或开发能够有效处理该系统产生的 $3 \mathrm{D}+\mathrm{T}$ 图像的软件。在本研究中，我们通过简单地修改几个参数追踪了从 SCAPE 系统获得的 $3 \mathrm{D}+\mathrm{T}$ 图像，这使我们能够获得可接受的结果（87% 的大细胞被正确追踪）。考虑到相对于其他数据集的较低性能可能来自分割较小、低强度细胞的困难（图 7B，上部和中部面板），通过进一步优化分割可能会改善结果。

我们还成功追踪了使用双光子显微镜监测的 3D MTCS 中的大量细胞（约 900 个），这一结果进一步支持了我们方法的广泛适用性。我们的方法无法追踪正在分裂或融合的细胞，或许多在记录期间进入视野的细胞。这是因为它在一个假设下运行，即每个细胞在另一个体积中都有唯一对应的细胞，以便匹配具有大运动的细胞。为了处理具有分裂、融合或进入的细胞，有必要将我们的算法与额外算法集成。

总之，我们已经证明 3DeeCellTracker 可以对在不同条件下获得的 $3 \mathrm{D}+\mathrm{T}$ 图像执行细胞分割和追踪。与在 $2 \mathrm{D}+\mathrm{T}$ 图像中追踪缓慢变形的细胞相比，在半约束/自由移动线虫大脑、跳动斑马鱼心脏或 3D 肿瘤球体中追踪细胞核是一项更具挑战性的任务，所有这些都在 3D 空间中经历相当大的运动。我们认为这是关于一个管道的首次报告，该管道能够高效且灵活地追踪来自多个、显著不同数据集的 $3 \mathrm{D}+\mathrm{T}$ 图像中的移动细胞。我们的方法应该能够对各种光学系统获得的 $3 \mathrm{D}+\mathrm{T}$ 图像中的细胞进行分割和追踪，这是一项尚未执行的任务。

---

## 材料与方法

### 关键资源表

（见原文中的关键资源表）

### 计算环境

我们的图像处理任务在具有 Intel Core i7-6800K CPU @ 3.40 GHz x 12 处理器、16 GB RAM 和 Ubuntu 16.04 LTS 64 位操作系统的个人计算机上执行。我们使用 NVIDIA GeForce GTX 1080 GPU（8 GB）训练和实现神经网络。神经网络使用运行在 TensorFlow 机器学习框架（Google, USA）之上的 Keras 高级神经网络 API（https://keras.io）构建和实现。除图像对齐在 ImageJ（NIH; RRID: SCR_003070）中实现，以及手动标注、手动校正和手动确认在 ITK-SNAP（RRID: SCR_002010; http://www.itksnap.org）或 IMARIS（Bitplane, UK; RRID: SCR_007370）中实现外，所有程序都在 Python 环境中实现。除了 ITK-SNAP 和 IMARIS，可以在 Python 环境中使用 napari（https://napari.org）。

### 预处理

**步骤 1：** 因为 2D 图像是沿 z 轴连续拍摄的，而不是同时拍摄的，所以 3D 体积的不同层之间可能存在小或大的位移。理想情况下，这应该在分割程序之前进行补偿。使用 ImageJ（NIH）中的 StackReg 插件（Thevenaz et al., 1998），我们通过使用刚体变换将每一层与中心层对齐来补偿位移，用于线虫 #1 和 #2 数据集。然而，我们没有在线虫 #3、#4、斑马鱼和肿瘤球体数据集中应用这种对齐，但仍然获得了可接受的结果，表明可以跳过此步骤。

**步骤 2：** 同一图像中的细胞可能具有非常不同的强度，检测弱细胞通常很困难。为了解决这个问题，我们通过滑动窗口（27×27×3 体素）应用局部对比度归一化（local contrast normalization）（Goodfellow et al., 2017），以便所有细胞具有相似的强度。这种归一化仅应用于核标记图像用于追踪，不影响红色荧光蛋白或 GECI 的信号强度计算。

### 3D U-Net

我们使用了与原始研究中显示的类似的 3D U-Net 结构（Çiçek et al., 2016）。网络接收 3D 图像作为输入，并生成相同大小的 3D 图像，每个体素的值在 0 和 1 之间，表示该体素属于细胞区域的概率（图 2-图补充 1）。我们为不同的成像条件使用了不同的 3D U-Net 结构，以便在 GPU 内存的限制内尽可能捕获每个细胞的信息。这种 U-Net 结构的修改是优选的但不是必需的。由于深度学习方法的灵活性，相同的结构可以在不同数据集上重用。图 2-图补充 1A 中显示的 3D U-Net 结构用于我们的数据集线虫 #1 和线虫 #2，它们具有相同的分辨率，但我们也成功地在具有非常不同分辨率的分箱斑马鱼数据集上使用了相同的结构（见下文）。对于数据集线虫 #3，它具有较低的分辨率，我们减少了最大池化和上采样操作的数量，以便最低层中的每个体素对应于与数据集线虫 #1 和线虫 #2 中相似的大小。由于较低的分辨率，我们还减少了输入、输出和中间层的大小。由于较小的结构占用较少的 GPU 内存，这允许我们增加每层上的卷积滤波器数量，从而增加网络的容量（见图 2-图补充 1B）。对于斑马鱼数据集，尽管它在 x 和 y 轴上的分辨率甚至更低，但由于斑马鱼心脏细胞的大小大于线虫神经元，我们使用了与数据集线虫 #1 和线虫 #2 中相同数量的最大池化和上采样操作。我们将 x、y 和 z 维度中的层大小调整为统一值（=64），因为斑马鱼数据集中三个维度的分辨率差异不大（图 2-图补充 1C）。为简单起见，我们重用了图 2-图补充 1 中的结构 A 和 B，用于线虫 #4、肿瘤球体和分箱斑马鱼数据集（见表 2）。

U-Net 可以使用非常少的标注图像进行训练（Ronneberger et al., 2015）。在本研究中，我们训练了六个 3D U-Net：（1）用于数据集线虫 #1 和 #2，（2）用于数据集线虫 #3，（3）用于自由移动数据集线虫 #4，（4）用于斑马鱼数据集，（5）用于数据集肿瘤球体，以及（6）用于分箱斑马鱼数据集。每个 3D U-Net 使用一个 3D 图像进行训练。注意，尽管数据集线虫 #1 和 #2 在信号强度和细胞运动方面存在显著差异，但使用了相同的训练 3D U-Net。使用 ITK-SNAP 软件（http://www.itksnap.org）将图像手动标注为细胞区域和非细胞区域。我们使用二元交叉熵作为损失函数来训练 3D U-Net。因为原始图像大小太大（512×1024×28、256×512×20、180×260×165 等）无法在 GPU 中计算，我们将原始图像分成适合三个 3D U-Net 结构输入大小的小子图像（160×160×16、96×96×8 或 64×64×64），并将子图像的细胞/非细胞分类组合以形成整个图像的最终分类。为了提高 3D U-Net 的性能，我们通过数据增强增加了训练数据：我们使用 Keras 中的"ImageDataGenerator"类对标注的 3D 图像应用随机仿射变换。仿射变换在 x-y 平面中受限，但在 z 方向不受限，因为线虫数据集和肿瘤球体数据集中 z 方向的分辨率远低于 x-y 平面（见图 3、图 3-图补充 1、2 和 3 以及图 8 的面板 A）。尽管斑马鱼数据集在 x、y 和 z 方向上具有相似的分辨率，但为简单起见，我们应用了相同的仿射变换。我们使用来自另一个独立于 #1 和 #2 但在相同光学条件下获得的数据集的 3D 图像训练了用于数据集线虫 #1 和 #2 的 U-Net，它在数据集线虫 #1 和 #2 上的分类仍然良好（图 3、图 3-图补充 1 和 2 的面板 C），表明 3D U-Net 具有优异的泛化能力。因为只有数据集可用于数据集线虫 #3、#4、斑马鱼心脏和肿瘤球体的特定分辨率，我们通过使用每个数据集的 $3 \mathrm{D}+\mathrm{T}$ 图像的第一个体积训练 3D U-Net，然后将 3D U-Net 应用于数据集的所有后续 3D 图像。

### 分水岭

3D U-Net 生成 0 和 1 之间的概率输出，表示体素属于类似细胞区域的概率。通过将阈值设置为 0.5，我们将 3D 图像分为类似细胞的区域（>0.5）和非细胞区域（≤0.5）。二值图像中的类似细胞区域进一步转换为距离图，其中每个值表示从当前体素到最近非细胞区域体素的距离。我们对距离图应用高斯模糊以平滑它，并搜索假设为细胞中心的局部峰值。然后我们使用这些中心作为种子应用分水岭分割（Beucher and Meyer, 1993）。分水岭分割应用两次；第一次应用是对每个 x-y 平面的 2D 分水岭分割，第二次应用是对整个 3D 空间的 3D 分水岭分割。需要两次分割是因为 x-y 平面和 z 维度的分辨率不同。

### 前馈网络：架构

初始匹配，即两个时间相邻体积中细胞之间的一组对应关系，是我们管道中细胞追踪的第一步，对最终追踪准确率至关重要。对应关系可以基于相对细胞位置进行估计，假设这些位置即使在器官变形期间也不会发生实质性变化。通过比较不同体积中两个细胞的相对位置的相似性，我们可以确定它们是否是同一细胞。

表示相对位置的一种传统方法是快速点特征直方图（fast point feature histograms, FPFH）（Rusu et al., 2009）。PR-GLS 研究（Ma et al., 2016）成功使用 FPFH 方法匹配人工点集数据集。然而，我们发现 FPFH 对本研究中考虑的数据集产生了较差的初始匹配（图 2-图补充 3A），可能是因为细胞的稀疏分布。因此，我们设计了一个三层前馈网络（FFN）来改进初始匹配（图 2B）。三层结构产生了与具有四层或六层的更复杂结构相当的良好匹配结果。通过比较两点之间的表示，网络生成两个细胞之间的相似性分数。基于 FFN 的相似性分数的初始匹配比 FPFH 方法实现的更准确（图 2-图补充 3B）。我们的 FFN + PR-GLS 方法产生的细胞位置预测比 FPFH + PR-GLS 和简单的仿射对齐方法（使用相干点漂移算法的实现：https://github.com/siavashk/pycpd）更准确（图 2-图补充 3C 和 D）。

在我们的 FFN 中，网络的输入包含两个点的位置信息。每个点由 20 个最近邻点的归一化位置表示（图 2B）。20 个最近邻位置（$\vec{d_1}, \vec{d_2}, ..., \vec{d_{20}}$）由 3D 向量给出，因为它们是从 3D 图像中提取的。为了归一化点，20 个位置中的每一个都除以平均距离 $d$（$d = \frac{1}{20}\sum_{k=1}^{20}|\vec{d_k}|$）。然后归一化位置按其绝对值升序排序。最后，平均距离 $d$ 作为最后一个值包含在内，因此每个点由 61D 向量表示。

我们利用第一个全连接层来计算每个点的相对位置的学习表示，作为 512D 向量（图 2B，输入后的第一个隐藏层）。然后我们对这两个 512D 向量应用第二个全连接层来比较两点的表示。得到的 512D 向量（输入后的第二个隐藏层）由第三个全连接层处理，以获得 0 和 1 之间的单个相似性分数，表示两个点来自同一细胞的概率。我们匹配两个不同体积中得分最高的两点，忽略这两点，并匹配得分次高的下一组两点。通过重复此过程，我们获得初始匹配（图 2C，面板 4-1）。

### 前馈网络：训练

在本研究中，我们仅基于数据集线虫 #3 的一个原始图像训练了一个 FFN，并在所有数据集（包括线虫、斑马鱼和肿瘤球体）中使用了该网络。为了训练网络，我们首先对数据集线虫 #3 的单个体积执行分割，并获得所有细胞中心的点集。因为我们需要大量匹配的点集进行训练，并且因为手动匹配点集既耗时又不切实际，我们通过对上述点集应用随机仿射变换并根据以下方程向每个点添加小的随机运动来创建合成训练数据集：

$$\vec{x'} = A\vec{x} + \vec{\epsilon_1} + \vec{\epsilon_2}$$

（另见图 2-图补充 2A 的说明）。这里 $\vec{x}$ 是原始点集中每个点的均值移除的 3D 位置 $\{x_1, x_2, x_3\}$，而 $\vec{x'}$ 是变换后的 3D 位置。$A$ 是应用随机仿射变换的矩阵。更具体地说，$A = I + U$，其中 $I$ 是 3×3 单位矩阵，$U$ 是 3×3 随机矩阵，每个元素 $U_{ij}$ 来自均匀分布。我们在本研究中使用了 $U_{ij} \sim \text{uniform}(-0.05, 0.05)$。$\vec{\epsilon_1}$ 是向点集中每个点添加随机运动的 3D 向量，而 $\vec{\epsilon_2}$ 是向点的一个子集（175 个细胞中的 20 个）添加更大随机运动的向量，以模拟分割程序中的严重错误。我们在本研究中使用了 $\epsilon_{1,i} \sim \text{uniform}(-2, 2)$ 和 $\epsilon_{2,i} \sim \text{uniform}(-5, 5)$。通过随机生成 $U_{ij}$、$\epsilon_{1,i}$ 和 $\epsilon_{2,i}$，我们可以从原始点集生成任意数量的具有新位置的新点集。之后，我们从每个生成的点集和原始点集中分别选择一个特定点 A 和另一个点 B，并计算它们的相对位置作为 FFN 的输入。在一半的情况下，点 A 和 B 是对应的，即它们来自同一细胞，而在另一半中，点 A 来自点 B 的细胞相邻的细胞，因此它们不对应。在本研究中，我们使用 576,000 个新生成的点 A 和 B 对来训练 FFN（图 1C）。我们使用二元交叉熵作为损失函数来训练 FFN。在训练期间，使用两个点集的独立测试数据集，FFN 匹配的性能逐渐提高（图 2-图补充 2B）。

### PR-GLS 方法

使用 FFN 计算的初始匹配使用 PR-GLS 方法中的期望最大化（expectation-maximization, EM）算法进行校正，如原始论文所述（Ma et al., 2016）。在原始研究中，初始匹配（通过 FPFH）在 EM 迭代期间重新计算；然而，在大多数数据集中，我们在执行 EM 步骤之前仅计算一次初始匹配（通过 FFN），这没有引起问题。仅对于具有非常大运动的数据集线虫 #4，我们每 10 次迭代后通过 FFN 重新计算初始匹配，以提高准确率。在 PR-GLS 校正之后，我们获得了从每个体积的点到后续体积的一致变换（图 2C，面板 4-2）。

### 单模式和集成模式

FFN + PR-GLS 可以从 $t-1$ 的细胞位置预测时间 $t$ 的新细胞位置；这是我们管道的默认模式，称为单模式（图 6C）。在足够高的采样率下，单模式是合理的，因为从 $t-1$ 到 $t$ 的运动远小于从 $t-i$（$i>1$）到 $t$ 的运动，使得从 $t-1$ 的预测更可靠。

当细胞运动非常大（例如在自由移动的线虫中）且采样率不足时，从 $t-1$ 到 $t$ 的预测变得不太可靠，从 $t-i$ 到 $t$ 的多个预测的平均值可能更准确。因此，我们开发了一种使用多个预测平均值的方法，称为集成模式（图 6C）。我们仅在线虫 #4 数据集上测试了此模式，该数据集具有相当大的运动（图 6B 和 10，以及表 3），因为集成模式的运行时间远长于单模式，即 FFN + PR-GLS 组件的运行时间与使用的预测数量成正比。具体来说，包括分割和追踪在内的线虫 #4 的运行时间在单模式下约为 30 体积/小时，在集成模式下为 6 体积/小时。

在集成模式中，我们计算来自先前时间点的最多 20 个预测的平均值。在 $t \leq 20$ 的情况下，平均值从时间点 $[t-1, t-2, ..., 1]$ 计算；在 $t > 20$ 的情况下，它在 $[t-d, t-2d, ..., t-20d]$ 上计算，其中 $d$ 是商 $(t-1)//20$。

### 追踪的精确校正

通过将 PR-GLS 方法应用于初始匹配，我们获得了更可靠的变换函数，其中所有明显不正确的匹配都被校正。然而，少数细胞中仍然存在小差异，如果不进行校正，这些差异可能随时间累积而变大。因此，我们包括了一个额外的自动校正步骤，其中每个细胞的中心位置稍微移向每个 3D U-Net 检测区域的中心（详情见图 2-图补充 4）。校正后，所有细胞都移动到估计位置，其形状与体积 #1 保持不变。对于大多数数据集，我们仅应用一次校正；对于线虫 #4 和肿瘤球体数据集，我们应用校正最多 20 次，直到达到收敛。如果多个细胞在新位置重叠，我们再次应用分水岭方法来分配它们的边界。在执行此步骤时，当沿 z 轴的分辨率远低于 x-y 平面中的分辨率时（即除线虫 #4 和斑马鱼外的所有数据集），我们基于体积 #1 的原始图像的插值计算追踪细胞区域的图像。我们这样做是为了获得每个细胞区域更准确的估计。

### 分割的手动校正

我们仅在体积 #1 中手动校正分割。我们将体积 #1 3D 图像的自动分割区域叠加到 ITK-SNAP 软件中的原始 3D 图像上，并丢弃假阳性区域，例如自发荧光区域和神经元突起。如果任何细胞未被检测到（假阴性错误），我们降低预处理中的噪声水平参数（表 1），这可以消除此类错误，或者我们在 ITK-SNAP 中手动添加这些细胞。过度分割和分割不足的区域通过考虑大多数细胞的大小和形状仔细校正。总体错误率取决于图像质量，但我们通常发现约 10% 的细胞需要手动校正，通常需要 2-3 小时（对于 100-200 个细胞）。

### 追踪结果的视觉检查

我们通过视觉检查每个体积中的追踪结果来统计所有细胞的追踪错误（图 1-图补充 2）。为了确认线虫神经元的追踪，我们将两个 $3 \mathrm{D}+\mathrm{T}$ 图像——原始图像和追踪标签——以顶部-底部排列组合，由 ImageJ 软件显示为超堆栈，以比较每个体积中的细胞位置。由于线虫数据集中的细胞主要在 x-y 平面移动（图 3F 和 9L，以及图 3-图补充 2F），我们观察每个 x-y 平面中原始图像和追踪标签之间的对应关系，以识别结果中的追踪错误。为了确认我们对肿瘤球体数据集的追踪，我们应用了相同的方法，尽管图像中有许多小的跨层运动（图 8F 和 G）。

对于自由移动线虫和斑马鱼心脏中的细胞，在超堆栈图像中确认追踪结果比半固定线虫和肿瘤球体更困难，因为细胞跨层的大运动频繁发生（图 6G 和 7G）。因此，我们将追踪标签的图像叠加到原始图像上，并将它们导入 IMARIS（Bitplane, UK），然后在 3D 模式下单独视觉检查每个细胞的追踪结果。对于具有重复振荡的斑马鱼数据集，我们从 1000 个体积中追踪并检查了所有 98 个细胞。由于自由移动线虫在三个方向上进行了不规则运动，视觉检查更具挑战性，因此我们仅追踪并检查了 1519 个原始体积中的初始 500 个体积的 3D 图像（图 6F）。

### 评估大运动

细胞的大运动是使追踪具有挑战性的一个问题。为了评估每个细胞运动的挑战性，我们将时间 $t$ 时细胞 A 的"相对运动"（RM）定义为：RM =（细胞 A 从 $t-1$ 到 $t$ 的运动）/（时间 $t$ 时细胞 A 与其最近相邻细胞之间的距离）。

图 4A 中间和右侧面板说明了在一维空间中移动的两个细胞，RM ≥ 0.5。在这种情况下，一个非常简单的追踪方法"在下一个时间点搜索最近的细胞"将错误地将 $t=2$ 时的细胞 A 匹配到 $t=1$ 时的细胞 B。因此，我们认为 RM ≥ 0.5 的运动比 RM < 0.5 的运动更具挑战性。

应该注意的是，大运动不是追踪的唯一挑战。例如，如果我们在所有细胞中评估追踪，斑马鱼数据集具有更高的错误率（表 3），这可能是由这些小细胞中的弱强度和光漂白引起的（图 7B 和 F; 图 7-图补充 1）。

### 提取活动

在从第一个体积到最后一个体积追踪线虫的神经元后，我们从对应于每个神经元的区域中提取活动。通过测量每个神经元在对应于 GECI 和位置标记的两个通道中的平均强度，活动计算为数据集线虫 #1 中的 GCaMP5G/tdTomato。我们类似地提取了斑马鱼数据集中心脏细胞的钙活动（GCaMP）和肿瘤球体数据集中的 FRET 活动。

### 我们的方法与另外两种方法的追踪准确率比较

因为 DeepCell 2.0 目前仅支持在 2D 数据集中追踪细胞，我们使用来自线虫数据集 #3 的两层图像（$z=9$ 和 $z=16$）测试了它，这些图像包括相对大量的细胞。我们排除了由于跨层运动而消失或出现的细胞，以进行公平比较。我们向 DeepCell 2.0 提供了来自我们方法的精确分割，以便专注于比较追踪算法的性能。

我们使用两个线虫数据集和一个斑马鱼数据集测试了 Toyoshima 的软件。对于斑马鱼数据集，我们仅测试了初始 100 个体积，因为他们的方法需要比我们的方法更长的图像处理时间（见表 5）。

对于这两种方法，我们与相应的作者进行了沟通，并尽最大努力根据他们的建议优化参数。尽管如此，这些分析可能可以进一步优化以适应我们的数据集。

### 我们的管道和先前方法在测试数据集上的运行时间

我们测试了我们的方法和先前方法在不同数据集上的运行时间（见表 5）。因为 DeepCell 2.0 目前只能追踪 $2 \mathrm{D}+\mathrm{T}$ 图像，运行时间通过使用一层的平均运行时间并乘以 21 层来估计，以便与我们的方法进行比较。结果，DeepCell 2.0 需要与我们的方法相当的运行时间。另一方面，Toyoshima 的软件处理线虫和斑马鱼数据集所需的时间远长于我们的方法。

在我们的方法中，使用我们自定义前馈网络的初始匹配以成对方式进行，因此时间复杂度为 $O(n^2)$，其中 $n$ 是检测到的细胞数量。在我们测试的具有 100-200 个细胞的数据集中，这不需要很长时间，例如，使用我们的台式 PC 在两个体积之间匹配 98 个细胞（斑马鱼）需要约 3.3 秒，或匹配 164 个细胞（线虫 #1a）需要约 8.6 秒。在 $n$ 太大的情况下，运行时间可能变得很长，例如，901 个细胞（肿瘤球体）需要约 4 分钟。如果 $n$ 和体积数量都太大，可能需要优化方法以减少运行时间，例如，通过限制在一组（100-200 个或更多）代表性细胞（例如大/亮细胞）中计算匹配，而其他非代表性细胞的运动可以从这些代表性细胞的运动估计，利用变形器官中这些运动的一致性。

### 线虫品系和培养

用于培养和处理秀丽隐杆线虫的技术基本上与先前描述的相同（Brenner, 1974）。TQ1101 lite-1(xu7) 和 AML14 都来自秀丽隐杆线虫遗传中心（University of Minnesota, USA）。在成像实验中使用年轻成年雌雄同体。

对于全神经元表达，NLS::tdTomato::NLS（Frøkjær-Jensen et al., 2016）和 NLS::GCaMP5G::NLS（其中 GCaMP5G（Akerboom et al., 2012）针对秀丽隐杆线虫进行了密码子优化，并在 N 和 C 末端连接到 NLS）使用 GATEWAY 系统（Thermo Fisher Scientific）与 rab-3 启动子融合（Stefanakis et al., 2015）。使用显微注射（Mello et al., 1992）将种系转化到 lite-1(xu7)（Liu et al., 2010），使用含有 pYFU251 rab-3p::NLS::GCaMP5G::NLS（25 ng/ml）、pYFU258 rab-3p::NLS::tdTomato::NLS（20 ng/ml）和 OP50 基因组（55 ng/ml）的溶液，以获得品系 KDK54165。品系 lite-1(xu7) 用于减少蓝光诱导的线虫感觉系统激活（Liu et al., 2010）。从注射获得的独立转基因品系产生了相似的结果。

### 线虫数据集

在本研究中，我们使用了四个线虫数据集。数据集线虫 #1 和 #2 中的 3D 图像使用我们自制的显微镜系统 OSB3D 获得（见下文）。数据集线虫 #1 和 #2 的线虫品系分别是 KDK54165（RRID: WB-STRAIN:KDK54165）和 AML14 wtfEx4[rab-3p::NLS::GCaMP6s: rab-3p::NLS::tagRFP]（RRID: WB-STRAIN:AML14）（Nguyen et al., 2016）。数据集线虫 #3 的 $3 \mathrm{D}+\mathrm{T}$ 图像先前已发布，使用线虫品系 JN2101 Is[H20p::NLS4::mCherry]; Ex[tax-4p::NLS-YC2.60, lin-44p::GFP]（Toyoshima et al., 2016）。自由移动线虫数据集（线虫 #4）的 $3 \mathrm{D}+\mathrm{T}$ 图像先前已发布，使用线虫品系 AML14（Nguyen et al., 2016; Nguyen et al., 2017）。在线虫 #4 数据集的 500 个体积中的三个（#79、#135 和 #406）中，大多数细胞从体积中消失或出现大量噪声，这使得数据集无法分析。因此，这些体积在追踪中被手动跳过，即假设细胞从先前体积未移动。

### 用于线虫大脑 $3 \mathrm{D}+\mathrm{T}$ 成像的转盘共焦系统

我们将我们的机器人显微镜系统（Tanimoto et al., 2017）升级为 3D 版本。我们使用了一个自制显微镜系统，该系统将 Nikon Eclipse Ti-U 倒置显微镜系统与 LV 聚焦模块和 FN1 Epi-fl 附件（Flovel, Japan）集成。激发光是来自 OBIS 488-60 LS（Coherent）的 488 nm 激光，被引入带有滤光轮控制器（分别为 CSU-X1 和 CSU-X1CU; Yokogawa, Japan）的共焦单元，以将旋转速度增加到 5,000 rpm。CSU-X1 配备了二向色镜（Di01-T-405/488/561, Semrock），将 488 nm 光反射到物镜（CFI S Fluor 40X Oil, Nikon, Japan），该物镜传输用于钙成像的 GCaMP 荧光和用于细胞位置标记的红色荧光。激光功率设置为 60 mW（100%）。荧光通过 CSU-X1 引入图像分光器（W-VIEW GEMINI, Hamamatsu, Japan），带有二向色镜（FF560-FDi01, Opto-line, Japan）和两个带通滤波器（BA495-540 和 BA570-625HQ, Olympus, Japan）。两个荧光图像并排捕获在 sCMOS 相机（ORCA Flash 4.0v3, Hamamatsu, Japan）上，该相机由具有 128 GB RAM 的 Precision T5810（Dell）计算机使用 HCImage Live 软件（Hamamatsu）在 Windows 10 Pro 上控制。一个实验的一系列图像（约 1-4 分钟）需要约 4-15 GB 的空间，在实验期间存储在内存中，然后传输到 1-TB USB 3.0 外部固态驱动器（TS1TESD400K, Transcend, Taiwan）进行进一步处理。

对于 3D 成像，物镜的 z 位置由带有压电控制器（E665）和 PIMikroMove 软件（PI, Germany）的压电物镜定位器（P-721）调节。压电运动和图像捕获的时序由来自 Arduino Uno（Arduino, Italy）的同步外部边沿触发器调节，每个步骤使用 35 ms 间隔，其中图像捕获为 29.9 ms。对于每个步骤，压电移动 1.5 mm，一个周期由 29 个步骤组成。我们丢弃了最顶部的步骤，因为它经常偏离正确位置，我们使用了剩余的 28 个步骤。注意，一个 3D 图像沿 z 轴的长度为 42 mm，这是基于神经元细胞体的典型直径（2-3 mm）和年轻成年线虫的身体（30-40 mm）确定的。每个周期需要 1015 ms；因此，每秒获得一个 3D 图像。这个条件对于监测神经元活动是合理的，因为线虫的神经元不产生动作电位（Goodman et al., 1998），并且许多神经元响应在秒级变化（Nichols et al., 2017）。我们还测试了一个条件，每个步骤使用 10 ms，曝光使用 4.9 ms，具有相同的步长和每个周期的步数（即每秒 2.3 个体积的 3D 图像），这产生了相当的结果。对于压电位置的循环调节，我们使用锯齿波而不是三角波来分配位置信息，因为锯齿波产生更准确的 z 位置，周期之间的方差更小。

### 斑马鱼心脏细胞

样品制备和成像先前已有描述（Voleti et al., 2019）。简而言之，GCaMP 和 dsRed 分别表达在心肌细胞的细胞质和细胞核中。使用 SCAPE 2.0 系统获得的 $3 \mathrm{D}+\mathrm{T}$ 图像进行了倾斜校正以考虑倾斜成像几何形状，并使用 3DeeCellTracker 进行分析。从本研究中获得的 3D 坐标用于在先前研究中提取细胞中的钙动态（Voleti et al., 2019）。

### 肿瘤球体

肿瘤球体根据先前的程序进行培养（Vinci et al., 2012; Yamaguchi et al., 2021）。简而言之，表达 FRET 型 ERK 传感器 EKAREV-NLS（Komatsu et al., 2011）的 HeLa 细胞（RRID: CVCL_0030, RCB0007, Riken Cell Bank; 经认证无支原体并使用 STR 分析进行验证）悬浮液以 1200 个细胞/孔的密度添加到 PrimeSurface 96 孔板（MS-9096U, Sumitomo Bakelite）中进行 3D 细胞培养。生长的球体转移到涂有 poly-L-lysine（Sigma-Aldrich）的 35 mm 培养皿中，并在含有 10% FBS 和 1% 青霉素和链霉素的 DMEM/F-12、无酚红（ThermoFisher）中进一步生长。

球体的 $3 \mathrm{D}+\mathrm{T}$ 图像使用配备水浸物镜（N25X-APO-MP 25x CFI APO LWD objective, Nikon）和高灵敏度砷化镓磷（GaAsP）检测器（A1R-MP+, Nikon）的双光子显微镜记录。使用由 Ti:Sapphire 激光器产生的 820 nm 光学脉冲进行激发。使用两个二向色镜（FF495-Di03 和 FF593-Di02, Opto-line）分离荧光，低于 495 nm 和 495-593 nm 之间的分离光由独立通道（分别为 CH1 和 CH2）检测。荧光信号积分四次以增加信噪比。每个步长沿 z 轴为 4 mm，每个体积由 54 个步骤组成，需要 5 分钟进行记录。在评估追踪准确率时，在事件发生后手动排除经历细胞死亡或细胞分裂的细胞。

### 代码可用性声明

用于追踪细胞和训练神经网络的代码、演示数据、神经网络的预训练权重以及代码的安装和使用说明可在 http://ssbd.qbic.riken.jp/set/20190602/（Demos190610.zip）获得。代码的更新版本可在 https://github.com/WenChentao/3DeeCellTracker 找到。使用代码和设置参数的指南也已包含在同一 GitHub 存储库中。

### 校样注释

在论文的原始版本中，我们使用基于包"3DeeCellTracker 0.2"的原始版本程序追踪数据集（见 https://pypi.org/project/3DeeCellTracker/#history 的版本信息）。当时追踪过程的运行时间未优化，这有时可能导致追踪的运行时间很长，特别是在集成模式和/或细胞数量很大时。此外，我们之前的追踪程序没有隐藏与最终用户无关的细节，也没有向用户提供关于中间分割/追踪结果的有用反馈。

为了解决这两个问题，我们首先使用 Python 中"NumPy"包可用的向量化技术改进了与"FFN"和"PR-GLS"相关的代码性能。我们还通过提取并仅执行一次循环中先前重复的计算，改进了与"精确校正"相关的代码性能。注意，我们没有更改与分割（3D U-Net + 分水岭）相关的程序，这可能仍需要相当长的时间，具体取决于图像大小和 3D U-Net 结构等因素。结果，我们的新程序在测试数据集中的速度提高了 1.7-6.8 倍（表 6）。这种加速在集成模式（线虫 #4）和细胞数量很大（3D 肿瘤球体）时尤其明显。其次，我们通过将细节移动到包中来简化程序。结果，用户可以通过在 Jupyter notebooks 中简单地运行几个命令来追踪细胞。我们还添加了新功能来显示分割和追踪的中间结果，以便用户现在可以使用这些结果来指导他们设置分割/追踪参数。要使用这些新功能，用户可以按照我们 GitHub 存储库中 README 文件中的更新说明安装最新版本的 3DeeCellTracker（当前为 0.4.0）并使用我们的 Jupyter notebooks。

---

## 致谢

我们感谢 Nobutoshi Odajima（Flovel Co. Ltd.）、Hideki Tanaka（Yokogawa Corp.）、Kenichi Matsumoto（Hamamatsu Photonics KK）和 Kazuma Etani（Nikon Solutions Co. Ltd.）建立 OSB-3D。我们还感谢 William Graf 和 David Van Valen 在测试 DeepCell 2.0 方面的友好建议，以及 Yu Toyoshima 在测试 Toyoshima 等人 2016 年软件方面的友好建议和帮助。我们还感谢 Toru Tamaki、Ichiro Takeuchi、Takuto Sakuma、Katsuyoshi Matsushita、Hiroyuki Kaneko、Taro Sakurai、Jared Young、Richard Yan、Yuto Endo 和 Kimura 实验室的其他成员对本研究的宝贵建议、评论和技术协助。线虫品系由秀丽隐杆线虫遗传中心（由 NIH 研究基础设施项目办公室 P40 OD010440 资助）提供。斑马鱼样品由 Kimara Targoff、Caitlin Ford 和 Carmen de Sena Tomás 提供，并在 Citlali Perez-Campos 和 Wenze Li 的协助下进行成像。

---

## 附加信息

### 资助

（见原文中的资助信息表）

### 作者贡献

Chentao Wen：概念化、数据管理、软件、形式分析、验证、调查、可视化、方法论、撰写-初稿、撰写-审阅和编辑；Takuya Miura：资源、调查；Venkatakaushik Voleti、Kei Yamamoto、Kohei Otomo、Yukako Fujie、Kazuhiro Aoki、Tomomi Nemoto：调查；Kazushi Yamaguchi、Motosuke Tsutsumi：数据管理、调查；Takayuki Teramoto：资源；Takeshi Ishihara：资源、撰写-审阅和编辑；Elizabeth MC Hillman：调查、撰写-审阅和编辑；Koutarou D Kimura：概念化、资源、监督、调查、项目管理、撰写-审阅和编辑

### 数据可用性

（见原文中的数据可用性部分）

---

## 参考文献

（见原文中的完整参考文献列表）

---

**翻译完成日期：** 2024 年

**翻译说明：** 本文档包含了论文的完整中文翻译，包括摘要、引言、结果、讨论、材料与方法等所有主要部分。翻译严格保持论文原意与学术风格，专有名词保留英文并括号解释，数学公式和符号照原样保留，句式尽量忠实原文逻辑。
